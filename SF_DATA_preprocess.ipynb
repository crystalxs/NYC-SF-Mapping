{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T20:17:37.781727Z",
     "start_time": "2019-01-18T20:17:36.322306Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import glob, os\n",
    "# from s2sphere import CellId, LatLng\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T20:17:46.502567Z",
     "start_time": "2019-01-18T20:17:46.493023Z"
    }
   },
   "outputs": [],
   "source": [
    "def local_datetime_from_timestamp(timestamp, tz_info):\n",
    "    utc_datetime = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    return utc_datetime.replace(tzinfo=pytz.timezone('UTC')).astimezone(tz_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T21:07:40.304844Z",
     "start_time": "2019-01-18T21:07:40.289664Z"
    }
   },
   "outputs": [],
   "source": [
    "def file_slicing(file_path):\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "    data.columns = [\"lat\", \"long\", \"occupied\", \"unixtime\"]\n",
    "    data['cab_name'] = pd.Series(file_path, index=data.index)\n",
    "    data_sort = data.sort_values(by=['cab_name', 'unixtime'])\n",
    "\n",
    "    data_sort['dt_ts'] = data_sort.apply(\n",
    "    lambda row: str(local_datetime_from_timestamp(row['unixtime'], pytz.timezone('America/Los_Angeles')))[:19],\n",
    "        axis = 1\n",
    "    )\n",
    "    data_sort = data_sort.reset_index(drop=True)\n",
    "\n",
    "    data_sort['last_occupied'] = data_sort.occupied.shift(+1)\n",
    "    data_sort['diff_occupied'] = data_sort['occupied'] - data_sort['last_occupied']\n",
    "    data_sort['is_pickup'] = (data_sort['diff_occupied'] == 1)\n",
    "    data_sort['is_dropoff'] = (data_sort['diff_occupied'] == -1)\n",
    "    \n",
    "    if data_sort.loc[0, 'occupied'] == 1:\n",
    "        data_sort.loc[0, 'is_pickup'] = True\n",
    "        data_sort.loc[0, 'is_dropoff'] = False\n",
    "\n",
    "    if data_sort.loc[len(data_sort)-1, 'occupied'] == 1:\n",
    "        data_sort.loc[len(data_sort)-1, 'is_dropoff'] = True\n",
    "        data_sort.loc[len(data_sort)-1, 'is_pickup'] = False\n",
    "\n",
    "    data_sliced = data_sort[(data_sort['is_pickup'] == True) | (data_sort['is_dropoff'] == True)]\n",
    "    data_sliced = data_sliced.reset_index(drop=True)\n",
    "    data_sliced = data_sliced.drop(['diff_occupied','occupied','cab_name'], axis=1)\n",
    "    return data_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T20:35:01.711500Z",
     "start_time": "2019-01-18T20:35:01.699202Z"
    }
   },
   "outputs": [],
   "source": [
    "def collapse_pick_drop(data_sliced, file_name):\n",
    "    # assert (len(data_sliced)%2 == 0)\n",
    "    data_start_end = pd.DataFrame()\n",
    "    i = 0\n",
    "    last_line = len(data_sliced) - 1\n",
    "\n",
    "    if data_sliced.loc[0,'is_dropoff']: # first line is dropoff\n",
    "        print(file_name, \": first line dropoff\")\n",
    "        # return\n",
    "    elif data_sliced.loc[len(data_sliced)-1,'is_pickup']: # last line is pickup\n",
    "        print(file_name, \": last line pickup\")\n",
    "        # return\n",
    "    elif sum(np.where(data_sliced['is_pickup'] , 1, 0)) != sum(np.where(data_sliced['is_dropoff'], 1, 0)):\n",
    "        print(file_name, \": pickup dropoff # not match\")\n",
    "        # return\n",
    "    else:\n",
    "\n",
    "        pick = data_sliced.iloc[::2]\n",
    "        pick = pick.reset_index(drop=True)\n",
    "        dropoff = data_sliced.iloc[1::2]\n",
    "        dropoff = dropoff.reset_index(drop=True)\n",
    "        if sum(np.where(pick['is_pickup'] == True, 0, 1)) == 0 and sum(np.where(dropoff['is_dropoff'] == True, 0, 1)) == 0:\n",
    "            data_joined = pick.merge(dropoff, left_index=True, right_index=True, how='inner')\n",
    "            data_joined = data_joined[['lat_y', 'long_y','lat_x', 'long_x', 'dt_ts_y', 'dt_ts_x']]\n",
    "            return data_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T21:07:43.105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_adkavy\n",
      "new_ackgrica\n",
      "new_iafstnue\n",
      "new_ogijtri\n",
      "new_umhenwed\n",
      "new_ovkojy\n",
      "new_obheujvo\n",
      "new_oygvar\n",
      "new_ekfrab\n",
      "new_ugatna\n",
      "new_eoivqued\n",
      "new_aldhidd\n",
      "new_ajthof\n",
      "new_iorjtwav\n",
      "new_ikujfurk\n",
      "new_upthin\n",
      "new_ancedvab\n",
      "new_eytups\n",
      "new_amnurgji\n",
      "new_ansyut\n",
      "new_ujtosh\n",
      "new_ainplin\n",
      "new_iagods\n",
      "new_isvayd\n",
      "new_aupclik\n",
      "new_askmecle\n",
      "new_epkiapme\n",
      "new_inlica\n",
      "new_ogdygdyd\n",
      "new_ubzachy\n",
      "new_igvidth\n",
      "new_ecdiwovu\n",
      "new_ilkedve\n",
      "new_ujhuki\n",
      "new_epemvagu\n",
      "new_imhacy\n",
      "new_ichikiga\n",
      "new_ojbaso\n",
      "new_eggfrij\n",
      "new_oiphye\n",
      "new_uvreoipy\n",
      "new_enjubpl\n",
      "new_ankped\n",
      "new_avpavi\n",
      "new_ecgojtyt\n",
      "new_ibflsruc\n",
      "new_ugifmav\n",
      "new_ioajdig\n",
      "new_ikkimm\n",
      "new_elbnaxa\n",
      "new_owgves\n",
      "new_ocjeng\n",
      "new_avglybic\n",
      "new_epabcadu\n",
      "new_idvowwed\n",
      "new_agcowktu\n",
      "new_ibgryk\n",
      "new_iatmeuns\n",
      "new_oadwowd\n",
      "new_eydadgio\n",
      "new_oilrag\n",
      "new_ucdewy\n",
      "new_idtwal\n",
      "new_odoywug\n",
      "new_inshfola\n",
      "new_eufdod\n",
      "new_ictmuog\n",
      "new_efgoaku\n",
      "new_edodblea\n",
      "new_ebstic\n",
      "new_owufrey\n",
      "new_ayshowg\n",
      "new_acgerl\n",
      "new_aggjuo\n",
      "new_omdrid\n",
      "new_afsfat\n",
      "new_ellimtbu\n",
      "new_ojumna\n",
      "new_atidfi\n",
      "new_ifragcic\n",
      "new_odlorhem\n",
      "new_aviltly\n",
      "new_okblahed\n",
      "new_eshroa\n",
      "new_oafhynu\n",
      "new_iawxben\n",
      "new_obceoo\n",
      "new_orsyalf\n",
      "new_iblool\n",
      "new_atsfiv\n",
      "new_iphespha\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('./data/sf/*.txt')\n",
    "# files = [files[4]]\n",
    "\n",
    "for file_path in files:\n",
    "\n",
    "    file_name = os.path.basename(file_path).split('.')[0]\n",
    "    print(file_name)\n",
    "    dirname = os.path.dirname(file_path)\n",
    "    new_file_path = os.path.join(\"./data/sf/output\".format(dirname), \"{}_collapsed.csv\".format(file_name))\n",
    "    data_sliced = file_slicing(file_path)\n",
    "    data_start_end = collapse_pick_drop(data_sliced, file_name)\n",
    "    if data_start_end is not None:\n",
    "        with open(new_file_path, 'w') as f:\n",
    "             data_start_end.to_csv(new_file_path, sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
